{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage examples for `py.ciu.image` package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code block contains all the `pip install`s that were executed when starting with a (more or less) empty environment. Included mainly FYI. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take care of all requirements. Comment away these if you have already installed as it should already!\n",
    "#!python3 -m pip install --upgrade pip\n",
    "#!pip install pandas\n",
    "#!pip install opencv-python\n",
    "#!pip install matplotlib\n",
    "#!pip install tensorflow\n",
    "#!pip install scikit-image\n",
    "\n",
    "# These are only needed if you want to develop source files directly in Jupyter Notebook\n",
    "#!pip install ipython --upgrade \n",
    "#%load_ext autoreload "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do all necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%autoreload 2\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "\n",
    "from CIU import CIU, SlicOcclusionPerturber, SuperpixelPerturber, SlicSegmenter, EntireSegmentStrategy, GaussianBlurDistortion, SingleColorDistortion, ReplaceImageDistortion, TransformDistortion\n",
    "from skimage.filters import gaussian, hessian\n",
    "from skimage.util import random_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import custom_object_scope, load_img, img_to_array\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.preprocessing import image\n",
    "from keras.applications import inception_v3 as inc_net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting bleeding in gastro-enterological images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Short example that takes pre-trained model, runs CIU on an image instance and then plots the original image and the image where only superpixels with bleeding detected are shown.\n",
    "We start by loading model and image to explain, as well as the function for manipulating all images to the format, colors etc expected by the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and set all needed parameters\n",
    "with custom_object_scope({'GlorotUniform': glorot_uniform()}):\n",
    "   model = keras.models.load_model('model_full_categorical.h5')\n",
    "#model = tf.keras.models.load_model(\"model_full_categorical.h5\")\n",
    "out_names = [\"NonBleeding\", \"Bleeding\"]\n",
    "\n",
    "# Images should pass through this function before they are given to the model.\n",
    "def transform_img_fn(path_list):\n",
    "    out = []\n",
    "    for img_path in path_list:\n",
    "        img = load_img(img_path, target_size=(150, 150))\n",
    "        x = img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = inc_net.preprocess_input(x)\n",
    "        out.append(x)\n",
    "    return np.vstack(out) / 2 + 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up bleeding and non-bleeding images used for testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_bleeding_imgnames = [\"Set1_4.png\",\"Set1_8.png\",\"Set1_22.png\",\"Set1_29.png\",\n",
    "                         \"Set1_53.png\",\"Set1_153.png\",\"Set1_157.png\",\"Set1_251.png\"]\n",
    "bleeding_imgnames = [\"Set1_674.png\",\"Set1_1128.png\",\"Set1_1151.png\",\"Set1_1201.png\",\n",
    "                     \"Set1_1277.png\",\"Set1_2812.jpg\",\"Set1_2879.bmp\",\"Set1_3068.bmp\",\n",
    "                     \"Set1_3078.bmp\",\"Set1_3105.bmp\",\"Set1_3141.bmp\",\"Set1_3190.bmp\"]\n",
    "imgnames = non_bleeding_imgnames + bleeding_imgnames\n",
    "imgpath = \"images/medical/\"\n",
    "imgpaths = [imgpath + item for item in imgnames]\n",
    "\n",
    "# Other approach\n",
    "imgs_vstack = transform_img_fn(imgpaths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We display all images to see what they look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all images\n",
    "ncol = len(imgpaths)\n",
    "fig, axes = plt.subplots(nrows=1, ncols=ncol, figsize=(8, 8))\n",
    "for i in range(0,len(imgs_vstack)): \n",
    "    axes[i].imshow(imgs_vstack[i])\n",
    "    axes[i].axis('off')\n",
    "    #axes[i].set_title(imgnames[i])\n",
    "plt.tight_layout() # Adjust spacing between images\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, that becomes too small when the number of images grows bigger, so let's use grid instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# Define the grid layout\n",
    "num_images_to_display = len(imgpaths)\n",
    "num_cols = 8\n",
    "num_rows = math.ceil(num_images_to_display/num_cols)\n",
    "\n",
    "# Function for plotting images in a grid\n",
    "def plotgrid(imgs_vstack, nrows, ncols, figsize=(10,4), figtitles=None):\n",
    "    total_subplots = nrows * ncols\n",
    "    n_imgs = len(imgs_vstack)\n",
    "    fig, axs = plt.subplots(nrows, ncols, figsize=figsize)\n",
    "    for i in range(nrows):\n",
    "        for j in range(ncols):\n",
    "            if i * ncols + j < n_imgs:\n",
    "                axs[i,j].imshow(imgs_vstack[i * ncols + j])\n",
    "                if figtitles is not None:\n",
    "                    axs[i,j].set_title(figtitles[i * ncols + j])\n",
    "                axs[i,j].axis('off')\n",
    "            else:\n",
    "                axs[i, j].axis('off')  # Turn off empty subplots\n",
    "    # Remove any excess empty subplots from the display\n",
    "    for i in range(n_imgs, total_subplots):\n",
    "        fig.delaxes(axs.flatten()[i])\n",
    "    plt.tight_layout() # Adjust spacing between images\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "plotgrid(imgs_vstack, num_rows, num_cols, figtitles=imgnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what the model predicts for all the images. We set up a \"pred_function\" to be used later in order to pass to CIU. CIU is model-agnostic so it needs to know how to get the predicted output values from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_function = model.predict_on_batch\n",
    "outvals = pred_function(imgs_vstack)\n",
    "for ov in outvals: \n",
    "    print(f\"The model output indicates {out_names[np.argmax(ov)]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the prediction function is not \"predict_on_batch\", it can be given as a parameter to ``CIU()``.\n",
    "\n",
    "Then we create a CIU object and \"explain\" why a particular image is \"Bleeding\" or \"NonBleeding\". A \"NonBleeding\" explanation would in this case normally contain all or most of the image, except for the black corners. \n",
    "\n",
    "For easier interpretation, we also show the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_to_xplain = 13 # Indices start from zero.\n",
    "image = imgs_vstack[img_to_xplain]\n",
    "perturber = SlicOcclusionPerturber(strategy=\"inverse\")\n",
    "\n",
    "# TESTING\n",
    "segmenter = SlicSegmenter(50, 10)\n",
    "strategy = EntireSegmentStrategy(inverse=True, fade_fun=gaussian, sigma=2, truncate=2)\n",
    "color_distortion = SingleColorDistortion((190,190,190))\n",
    "blur_distortion = GaussianBlurDistortion(sigma=30, truncate=1)\n",
    "replace_distortion = ReplaceImageDistortion(np.array([imgs_vstack[1]]))#, imgs_vstack[10]]))\n",
    "hessian_distortion = TransformDistortion(hessian)\n",
    "noise_distortion = TransformDistortion(random_noise, mode='s&p', amount=0.4) \n",
    "#perturber = SuperpixelPerturber(segmenter, strategy, noise_distortion)\n",
    "# TESTING\n",
    "\n",
    "\n",
    "\n",
    "ciu_object = CIU(model, out_names, perturber=perturber, inverse=True)\n",
    "tic = time.perf_counter()\n",
    "ciu_sp_result = ciu_object.Explain(image)\n",
    "toc = time.perf_counter()\n",
    "print(f\"Done in {toc - tic:0.4f} seconds\")\n",
    "# Display CI and CU values for \"winning\" class\n",
    "winner = np.argmax(ciu_sp_result[\"outvals\"])\n",
    "print(f\"CI values of winner class are:\\n {ciu_sp_result['CI'][winner,:]}\")\n",
    "print(f\"CU values of winner class are:\\n {ciu_sp_result['CU'][winner,:]}\")\n",
    "print(f\"Cinfl values of winner class are:\\n {ciu_sp_result['Cinfl'][winner,:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be useful to display a histogram of CI values for finding a suitable threshold value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and show histogram plot\n",
    "CIU_val = \"Cinfl\"\n",
    "vals = ciu_sp_result[CIU_val][winner,:]\n",
    "plt.hist(vals, bins=30, density=True, alpha=0.6, color='b')\n",
    "plt.xlabel(f'{CIU_val} value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title(f'Distribution of {CIU_val} values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the corresponding result, together with original image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include at least one superpixel\n",
    "max_CI = vals.max()\n",
    "own_CI_limit = 0.1\n",
    "img = ciu_object.ImageInfluentialSegmentsOnly(winner, min(max_CI, own_CI_limit))\n",
    "# Commented out the simple display of \"explanation image\" only\n",
    "#plt.imshow(img)\n",
    "#plt.show()\n",
    "print(f\"The image is {imgnames[img_to_xplain]}\")\n",
    "print(f\"The model output indicates {out_names[np.argmax(outvals[img_to_xplain])]}\")\n",
    "fig, axes = plt.subplots(1, 2, figsize=(8,8))\n",
    "axes[0].imshow(imgs_vstack[img_to_xplain])\n",
    "axes[0].axis('off')\n",
    "axes[1].imshow(img)\n",
    "axes[1].axis('off')\n",
    "plt.tight_layout() # Adjust spacing between images\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the segments/superpixels and plot their borders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from scipy import ndimage\n",
    "from skimage import io, color, segmentation, exposure\n",
    "from skimage.segmentation import mark_boundaries\n",
    "\n",
    "# Get the segments\n",
    "segment_boundaries = segmentation.mark_boundaries(ciu_object.original_image, ciu_object.superpixels)\n",
    "\n",
    "# Display the original image with superpixel boundaries\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(121), plt.imshow(ciu_object.original_image), plt.title('Original Image')\n",
    "plt.subplot(122), plt.imshow(segment_boundaries), plt.title('Superpixel Boundaries')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the explanations for all images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_imgs = []\n",
    "per_imgs = []\n",
    "seg_imgs = []\n",
    "def_CI_limit = 0.01\n",
    "tic = time.perf_counter()\n",
    "for i in range(0,len(imgpaths)):\n",
    "    cius = ciu_object.Explain(imgs_vstack[i])\n",
    "    win_class = np.argmax(cius[\"outvals\"])\n",
    "    CI_limit = min(def_CI_limit, cius[\"CI\"][win_class,:].max())\n",
    "    oimg = ciu_object.ImageInfluentialSegmentsOnly(win_class, CI_limit, use_perturber=True)\n",
    "    pimg = np.squeeze(replace_distortion(np.expand_dims(ciu_object.image, axis=0), ciu_object.get_influential_segments(win_class, CI_limit)), axis=(0,1))\n",
    "    simg = ciu_object.masks[0][20][0]\n",
    "    #print(oimg.shape, pimg[0].shape, simg.shape)\n",
    "    out_imgs.append(oimg)\n",
    "    per_imgs.append(pimg[0])\n",
    "    seg_imgs.append(simg)\n",
    "toc = time.perf_counter()\n",
    "print(f\"Done in {toc - tic:0.4f} seconds\")\n",
    "plotgrid(out_imgs, num_rows, num_cols)\n",
    "plotgrid(per_imgs, num_rows, num_cols)\n",
    "plotgrid(seg_imgs, num_rows, num_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot original images with names again, for easier comparison. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotgrid(imgs_vstack, num_rows, num_cols, figtitles=imgnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default CI limit wasn't appropriate for images 2812 and 3068. By plotting the histogram of CI values for them (see earlier), we get the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cius1 = ciu_object.Explain(imgs_vstack[13])\n",
    "win_class = np.argmax(cius1[\"outvals\"])\n",
    "oimg1 = ciu_object.ImageInfluentialSegmentsOnly(win_class, 0.05)\n",
    "cius2 = ciu_object.Explain(imgs_vstack[15])\n",
    "win_class = np.argmax(cius2[\"outvals\"])\n",
    "oimg2 = ciu_object.ImageInfluentialSegmentsOnly(win_class, 0.05)\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(4, 4))\n",
    "axes[0].imshow(oimg1)\n",
    "axes[0].axis('off')\n",
    "axes[1].imshow(oimg2)\n",
    "axes[1].axis('off')\n",
    "plt.tight_layout() # Adjust spacing between images\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
